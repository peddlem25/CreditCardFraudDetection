# -*- coding: utf-8 -*-
"""Copy of Week3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F7bZBxmiN-Uc_ritmUh1RHVdykUMaIWF

#FRAUD DETECTION

Our Tasks:
  
  - Explore the datasets/ Visualize
  - Decide which features are important
  - Preform Machine Learning
  - Test the model on the testing set
  ***Credit card Data is comign from a Kaggle Dataset and uploaded to google drive named 'creditcard.csv'
  
  If Class-in-balance in datasets use the clustering method.
  ***Reminder, uploaded files will get deleted when this runtime is recycled, this included the creditcard.csv data file.
"""

import numpy as np
import sklearn as sk
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import scale
import random

df = pd.read_csv('creditcard.csv', low_memory=False)
df = df.sample(frac=1).reset_index(drop=True)
df.head()

"""The following show's how many Fraud and Non Fraud cases their are"""

fraud = df.loc[df['Class'] == 1]
non_frauds = df.loc[df['Class'] == 0]
print(len(fraud))
print(len(non_frauds))

"""Visualize the *Fraud* VS the *Non Fraud* cases in dollar based transaction sizes."""

labels = 'Fraud Cases', 'Non-Fraud'
sizes = [177, 71218]
explode = (0.1, 0.0)  # only "explode" the 2nd slice (i.e. 'Fraud Cases')

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

ax = fraud.plot.scatter(x='Amount', y='Class', color='Orange', label='Fraud')
non_frauds.plot.scatter(x='Amount', y='Class', color='Blue', label='Normal', ax=ax)
plt.show()

"""As we can see most if not all Fraud cases are in the amounts less than $5000.

#Machine Learning Time
"""

from sklearn import linear_model
from sklearn.model_selection import train_test_split

"""**Train** 35%/ Test 65%"""

x = df.iloc[:, :-1]
y = df['Class']

X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.35)

"""*1e5* = 100,000. C is a penalty term, used to disincentivize and regulate against over fig."""

logistic = linear_model.LogisticRegression(C=1e5)
logistic.fit(X_train, Y_train)
print('Score;', logistic.score(X_test, Y_test))

"""/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
Score; 0.9989968199191437

**Score** is 0.9989%
"""

y_predicted = np.array(logistic.predict(X_test))
print(y_predicted)

"""[0 0 0 ... 0 0 0]

**Most** is not fraud
"""